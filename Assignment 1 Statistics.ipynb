{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d98ca7",
   "metadata": {},
   "source": [
    "Group 09: Luu Thu Trang (2695303) and Raminta Povilaityte (2692655)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f2f76",
   "metadata": {},
   "source": [
    "# Checklist:\n",
    "- Prepare your submission using this template;\n",
    "- Fill out the group number, member names and student IDs above;\n",
    "- Adjust assignement number above;\n",
    "- Type up your answers below using Latex and/or Python as exemplified;\n",
    "- Don't add the text of the question below, only your answers;\n",
    "- To create a PDF of your submission go to [File] > [Download as] > [PDF via LaTeX (.pdf)];\n",
    "- Delete this cell before creating the PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05979061",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72f69f",
   "metadata": {},
   "source": [
    "## (Example)\n",
    "\n",
    "If $X$ has a $Bin(n,p)$ distribution, then \n",
    "$$\n",
    "\\mathbb{P}(X=k) = \n",
    "{n \\choose k} p^k (1-p)^{n-k}, \n",
    "\\quad k=0,\\dots,n.\n",
    "$$\n",
    "We then have that $Y = n-X$ satisfies\n",
    "$$\n",
    "\\mathbb{P}(Y=k) = \n",
    "\\mathbb{P}(n-X=k) =\n",
    "\\mathbb{P}(X=n-k) = {n \\choose k} p^{n-k} (1-p)^k, \n",
    "\\quad k=0,\\dots,n,\n",
    "$$\n",
    "so that $Y$ has a $Bin(n,1-p)$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c176cdf",
   "metadata": {},
   "source": [
    "## (a)\n",
    "To compute Bias of $\\hat\\lambda$ and $\\tilde\\lambda$ we use the following formula: \n",
    "$$\n",
    "Bias(\\hat{\\theta}) = {E}(\\hat{\\theta}) -  \\theta\n",
    "$$\n",
    "To apply this formula we first find ${E}(\\hat{\\lambda})$ for $\\hat{\\lambda}$ : \n",
    "$$\n",
    "{E}(\\hat{\\lambda}) = {E}(\\frac{(\\overline{X})^2}{9}) = \\frac{1}{9}{E}((\\overline{X})^2) = \\frac{1}{9}{E}(X)^2  =  \\frac{1}{9} (3\\sqrt{\\lambda})^2 = \\lambda\n",
    "$$\n",
    "We plug in the above expectation of $\\hat{\\lambda}$ in Bias formula to find :\n",
    "$$\n",
    "Bias(\\hat{\\lambda}) = {E}(\\hat{\\lambda}) -  \\lambda =  \\lambda -  \\lambda = 0\n",
    "$$\n",
    "We can conclude that $\\hat{\\lambda}$ is an unbiased estimator of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2abff1",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Continue using the formula from (a), we have:\n",
    "$$\n",
    "{E}(\\tilde{\\lambda}) = {E}(\\frac{\\sum_{i=1}^n({X_i})^2}{12n}) = \\frac{1}{12n}{E}(\\sum_{i=1}^n({X_i})^2) \n",
    "= \\frac{1}{12n}({E}(X_1)^2 + ... + {E}(X_n)^2) \n",
    "=  \\frac{1}{12n} \\times 12\\lambda n = \\lambda\n",
    "$$\n",
    "We plug in the above expectation of $\\hat{\\lambda}$ in Bias formula to find :\n",
    "$$\n",
    "Bias(\\tilde{\\lambda}) = {E}(\\tilde{\\lambda}) -  \\lambda =  \\lambda -  \\lambda = 0\n",
    "$$\n",
    "We can conclude that $\\tilde{\\lambda}$ is an unbiased estimator of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25462cc",
   "metadata": {},
   "source": [

    "## (b)\n",
    "Continue using the formula from (a), we have:\n",
    "$$\n",
    "{E}(\\tilde{\\lambda}) = {E}(\\frac{\\sum_{i=1}^n({X_i})^2}{12n}) = \\frac{1}{12n}{E}(\\sum_{i=1}^n({X_i})^2) \n",
    "= \\frac{1}{12n}({E}(X_1)^2 + ... + {E}(X_n)^2) \n",
    "=  \\frac{1}{12n} \\times 12\\lambda n = \\lambda\n",
    "$$\n",
    "We plug in the above expectation of $\\hat{\\lambda}$ in Bias formula to find :\n",
    "$$\n",
    "Bias(\\tilde{\\lambda}) = {E}(\\tilde{\\lambda}) -  \\lambda =  \\lambda -  \\lambda = 0\n",
    "$$\n",
    "We can conclude that $\\tilde{\\lambda}$ is an unbiased estimator of $\\lambda$"

    "## (c)\n",
    "Suppose that: \n",
    "$${V}(\\hat{\\lambda})=\\frac{2\\lambda^2}{n}\n",
    "$$\n",
    "Then we compute the MSE (Mean Squared Error) for $\\hat{\\lambda}$ using the MSE formula:\n",
    "\n",
    "$$ MSE_\\hat{\\lambda}(\\lambda) = Bias(\\hat{\\lambda})^2 + {V}(\\hat{\\lambda})\n",
    "$$\n",
    "\n",
    "By using the fact that $\\hat{\\lambda}$ is an unbiased estimator from part a) and plugging in the given expression for $ {V}(\\hat{\\lambda})$ we find $MSE_\\hat{\\lambda}(\\lambda)$ to be the following : \n",
    "$$ MSE_\\hat{\\lambda}(\\lambda) = 0^2 + \\frac{2\\lambda^2}{n} = \\frac{2\\lambda^2}{n}\n",
    "$$\n"

   ]
  },
  {
   "cell_type": "markdown",
    
   "id": "6c73744d",

   "metadata": {},
   "source": [
    "## (d)\n",
    "To calculate the $MSE_{\\tilde{\\lambda}}(\\lambda)$, we use the formula from (c).\n",
    "\n",
    "We will first calculate $Var(\\lambda) = {V}_{\\lambda}(\\tilde{\\lambda})$. \n",
    "$$\n",
    "{V}_{\\lambda}(\\tilde{\\lambda}) = {V}(\\frac{\\sum_{i=1}^n({X_i})^2}{12n})\n",
    "$$\n",
    "$$\n",
    "= (\\frac{1}{12n})^2({V}(X_1)^2 + ... +{V}(X_n)^2) \n",
    "= (\\frac{1}{12n})^2\\times n{V}(X)^2\n",
    "$$\n",
    "$$\n",
    "=\\frac{1}{12n}\\times ({E}X^4 - ({E}X^2)^2)\n",
    "=\\frac{1}{12n}\\times (360\\lambda^2 - (12\\lambda)^2)\n",
    "$$\n",
    "$$\n",
    "=\\frac{1}{12n}\\times (360\\lambda^2 - 144\\lambda^2)\n",
    "=\\frac{216\\lambda^2}{12n} = \\frac{18\\lambda^2}{n}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$MSE_{\\tilde{\\lambda}}(\\lambda) = 0 + \\frac{18\\lambda^2}{n} = \\frac{18\\lambda^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a302f7",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc1d76",
   "metadata": {},
   "source": [
    "## (a)\n",
    "To compute Maximum Likelihood Estimator (MLE) for $\\beta$ we first find the likelihood function (pdf of the sample) as follows:\n",
    "\n",
    "$$ \n",
    "{L} (\\beta ; X_1, ... , X_n) = \\beta e ^{-\\beta x_1} \\cdot \\beta e ^{-\\beta x_2} \\cdot ... \\cdot \\beta e ^{-\\beta x_n} = \\beta^{n} e ^{-\\beta \\sum_{i=1}^{ n}x_i} = \\beta^{n} e ^{-\\beta n \\overline{X}} \n",
    "$$\n",
    "\n",
    "Then we find a log-likelihood function : \n",
    "\n",
    "$$ \n",
    "{l} (\\beta ; X_1, ... , X_n) = n \\log{\\beta} - \\beta n \\overline{X}\n",
    "$$\n",
    "\n",
    "To find an MLE($\\beta$) we take the derivative of log-likelihood in terms of $\\beta$ :\n",
    "\n",
    "$$ \n",
    "\\frac {\\partial{l}}{\\partial{\\beta}}  = \\frac {n}{\\beta} - n \\overline{X} = 0\n",
    "$$\n",
    "\n",
    "Find MLE we solve the above equation for $\\beta$ to find: \n",
    "\n",
    "$$\n",
    "\\beta = \\frac{n}{n\\overline{X}} = \\frac{1}{\\overline{X}} = \\hat{\\beta}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\beta}$ is the MLE of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68edd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([1,3,4,5,2,3,4,5,6,7])\n",
    "m = sum(data)/len(data)\n",
    "v2 = sum((data-m)**2)/len(data)\n",
    "print(m,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0814b87",
   "metadata": {},
   "source": [
    "## (b)\n",
    "To calculate the Method of Moments Estimator for $\\beta$ based on the first moment of $X$. We first calculate the first moment of $X$. This is exactly the expectation of X.\n",
    "$$\n",
    "{E}X = \\frac{1}{\\beta} = g_1(\\beta)\n",
    "$$\n",
    "\n",
    "Now we solve the equation: $$\\overline{X} = g_1(\\tilde{\\beta}) <=> \\overline{X} = \\frac{1}{\\tilde{\\beta}} <=> \\tilde{\\beta} = \\frac{1}{\\overline{X}}$$\n",
    "\n",
    "So $\\tilde{\\beta} = \\frac{1}{\\overline{X}}$ is an estimator of $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d9ab6",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Second moment of X is found as follows: \n",
    "$$\n",
    "{E}X^2 = {V}(X)+({E}(X))^2 = \\frac{1}{\\beta^2} + \\frac{1}{\\beta^2} = \\frac{2}{\\beta^2}\n",
    "$$\n",
    "We solve: \n",
    "$$ \\overline{X^2} = \\frac{2}{\\beta^2}   \\leftrightarrow  \n",
    "\\beta^2 = \\frac{2}{\\overline{X^2}}    \\leftrightarrow $$ <br>\n",
    "$$\n",
    "\\tilde{\\beta} = \\sqrt{\\frac{2}{\\overline{X^2}}}\n",
    "$$ \n",
    "where $\\tilde{\\beta}$ is the MME for $\\beta$ based on the second moment of X "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc086e9",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f55dd",
   "metadata": {},
   "source": [
    "## (a)\n",
    "We know that the prior on $p$ has a $Beta(2,3)$ distribution. \n",
    "\n",
    "$Beta$ distribution has the following probability density function:\n",
    "$$ f_X(t) = \\frac{t^{\\alpha -1}(1-t)^{\\beta - 1}}{B(\\alpha,\\beta)}$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\pi(p)\\propto \\frac{p^{\\alpha -1}(1-p)^{\\beta - 1}}{B(\\alpha,\\beta)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi(p)\\propto p^{2 -1}(1-p)^{2 - 1} = p(1-p)^2\n",
    "$$\n",
    "\n",
    "To find the mode of the prior, we use the following formula:\n",
    "\n",
    "Mode of a $Beta(\\alpha,\\beta)$ distribution is $\\frac{\\alpha -1}{\\alpha + \\beta -2}$\n",
    "\n",
    "So the most likely value of $p$ is:\n",
    "\n",
    "$$\\frac{2 -1}{2 + 3 - 2} = \\frac{1}{3}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcee111",
   "metadata": {},
   "source": [
    "## (b)\n",
    "To calculate the Method of Moments Estimator for $\\beta$ based on the first moment of $X$. We first calculate the first moment of $X$. This is exactly the expectation of X.\n",
    "$$\n",
    "{E}X = \\frac{1}{\\beta} = g_1(\\beta)\n",
    "$$\n",
    "\n",
    "Now we solve the equation: $$\\overline{X} = g_1(\\tilde{\\beta}) <=> \\overline{X} = \\frac{1}{\\tilde{\\beta}} <=> \\tilde{\\beta} = \\frac{1}{\\overline{X}}$$\n",
    "\n",
    "So $\\tilde{\\beta} = \\frac{1}{\\overline{X}}$ is an estimator of $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "We know that the prior on $p$ has a $Beta(2,3)$ distribution. \n",
    "\n",
    "$Beta$ distribution has the following probability density function:\n",
    "$$ f_X(t) = \\frac{t^{\\alpha -1}(1-t)^{\\beta - 1}}{B(\\alpha,\\beta)}$$\n",
    "\n",

    "Then,\n",
    "$$\n",
    "\\pi(p)\\propto \\frac{p^{\\alpha -1}(1-p)^{\\beta - 1}}{B(\\alpha,\\beta)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi(p)\\propto p^{2 -1}(1-p)^{2 - 1} = p(1-p)^2\n",
    "$$\n",
    "\n",
    "To find the mode of the prior, we use the following formula:\n",
    "\n",
    "Mode of a $Beta(\\alpha,\\beta)$ distribution is $\\frac{\\alpha -1}{\\alpha + \\beta -2}$\n",
    "\n",
    "So the most likely value of $p$ is:\n",
    "\n",
    "$$\\frac{2 -1}{2 + 3 - 2} = \\frac{1}{3}$$\n",

    "We are given the sample size $n = 20$ with $x = 13$ successes and $n-x = 7$ failures.\n",
    "\n",
    "$$\n",
    "\\pi(p|X) = \\frac{f_p(x) \\cdot \\pi(p)}{f(x)} \\propto f_p(x) \\cdot \\pi(p) \n",
    "$$\n",
    "\n",
    "$$\n",
    "f_p(x) \\cdot \\pi(p) = p(p-1)^2 \\cdot {n \\choose x} p^x(1-p)^{n-x}\\propto p(p-1)^2 \\cdot p^x(1-p)^{n-x} = p^{x+1}(1-p)^{n-x+2}\n",
    "$$\n",
    "\n",
    "The latter expression suggests that the posterior $\\pi(p|X)$ would be $Beta(\\alpha, \\beta)$ distribution. Next we find the posterior parameters:\n",
    "\n",
    "$$\n",
    "\\alpha -1 = x + 1 \\leftrightarrow \\boldsymbol{\\alpha = x + 2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta - 1 = n - x + 2 \\leftrightarrow \\boldsymbol{\\beta = n - x + 3}\n",
    "$$\n",
    "\n",
    "Therefore we find the posterior distribution with plugged in values for $n$ and $x$ to be the following:\n",
    "\n",
    "$$\n",
    "\\pi(p|X) \\sim Beta(x + 2,n - x + 3) = Beta (15, 4)\n",
    "$$\n"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "dfb46a3b",

   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
